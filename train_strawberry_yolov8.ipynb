{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üçì Strawberry Detection - Direct YOLOv8 Training Notebook\n",
    "\n",
    "This notebook provides a **direct, ready-to-run** solution for training YOLOv8 models on your strawberry dataset.\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "1. **Run all cells** in order (Cell ‚Üí Run All)\n",
    "2. **Dataset will be automatically downloaded** from Kaggle\n",
    "3. **Choose model** (YOLOv8m or YOLOv8l)\n",
    "4. **Monitor training** with real-time plots\n",
    "5. **Download results** when complete\n",
    "\n",
    "## üìä Current Status\n",
    "\n",
    "- ‚úÖ **YOLOv8n**: Trained (0.989 mAP@50)\n",
    "- ‚úÖ **YOLOv8s**: Trained (98.5% mAP@50)\n",
    "- ‚è≥ **YOLOv8m**: Ready for training\n",
    "- ‚è≥ **YOLOv8l**: Ready for training\n",
    "\n",
    "## ‚öôÔ∏è Hardware Requirements\n",
    "\n",
    "- **Minimum**: 8GB GPU VRAM (RTX 3070/2070)\n",
    "- **Recommended**: 10GB+ GPU VRAM (RTX 3080/3090)\n",
    "- **CPU**: 4+ cores, 16GB RAM\n",
    "- **Storage**: 10GB free space for models\n",
    "\n",
    "## üí∞ Estimated Training Times\n",
    "\n",
    "| Model | Epochs | RTX 3080 | RTX 3090 | Cost (RTX 3080) |\n",
    "|-------|--------|----------|----------|-----------------|\n",
    "| YOLOv8m | 120 | 3-4 hours | 2.5-3.5 hours | $0.51-$0.68 |\n",
    "| YOLOv8l | 150 | 4-5 hours | 3-4 hours | $0.68-$0.85 |\n",
    "\n",
    "**Total for both**: 7-9 hours, ~$1.19-$1.53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Dataset Download from Kaggle\n",
    "\n",
    "This cell will download the fruit ripeness dataset from Kaggle and prepare it for YOLOv8 training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages including kaggle\n",
    "!pip install ultralytics torch torchvision opencv-python matplotlib Pillow tqdm tensorboard kaggle -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def download_kaggle_dataset():\n",
    "    \"\"\"Download and prepare the Kaggle fruit ripeness dataset.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üì• DOWNLOADING KAGGLE DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Kaggle dataset details\n",
    "    kaggle_dataset = \"dudinurdiyansah/fruit-ripeness-dataset\"\n",
    "    dataset_dir = \"model/dataset_strawberry_kaggle\"\n",
    "    \n",
    "    # Check if dataset already exists\n",
    "    if os.path.exists(dataset_dir) and os.path.exists(os.path.join(dataset_dir, \"data.yaml\")):\n",
    "        print(f\"‚úÖ Dataset already exists at: {dataset_dir}\")\n",
    "        print(\"Skipping download...\")\n",
    "        return dataset_dir\n",
    "    \n",
    "    # Create directory\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Download using kaggle CLI\n",
    "        print(f\"Downloading dataset: {kaggle_dataset}\")\n",
    "        !kaggle datasets download -d {kaggle_dataset} -p {dataset_dir}\n",
    "        \n",
    "        # Find the downloaded zip file\n",
    "        zip_files = list(Path(dataset_dir).glob(\"*.zip\"))\n",
    "        if not zip_files:\n",
    "            print(\"‚ùå No zip file found after download\")\n",
    "            return None\n",
    "            \n",
    "        zip_path = zip_files[0]\n",
    "        print(f\"Extracting: {zip_path.name}\")\n",
    "        \n",
    "        # Extract zip file\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dataset_dir)\n",
    "        \n",
    "        # Remove zip file\n",
    "        os.remove(zip_path)\n",
    "        \n",
    "        # Look for the actual dataset structure\n",
    "        extracted_dirs = list(Path(dataset_dir).glob(\"*\"))\n",
    "        for item in extracted_dirs:\n",
    "            if item.is_dir():\n",
    "                # Check if this looks like the dataset\n",
    "                train_dir = item / \"train\"\n",
    "                valid_dir = item / \"valid\"\n",
    "                \n",
    "                if train_dir.exists() and valid_dir.exists():\n",
    "                    # Move contents up one level\n",
    "                    for subitem in item.glob(\"*\"):\n",
    "                        shutil.move(str(subitem), str(dataset_dir / subitem.name))\n",
    "                    # Remove the now-empty directory\n",
    "                    shutil.rmtree(item)\n",
    "                    break\n",
    "        \n",
    "        # Create data.yaml if it doesn't exist\n",
    "        data_yaml_path = os.path.join(dataset_dir, \"data.yaml\")\n",
    "        if not os.path.exists(data_yaml_path):\n",
    "            print(\"Creating data.yaml configuration...\")\n",
    "            \n",
    "            # Find class names from directory structure\n",
    "            train_path = os.path.join(dataset_dir, \"train\")\n",
    "            if os.path.exists(train_path):\n",
    "                # Look for label files to determine classes\n",
    "                label_files = list(Path(train_path).glob(\"labels/*.txt\"))\n",
    "                if label_files:\n",
    "                    # Read first label file to get class IDs\n",
    "                    with open(label_files[0], 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                    class_ids = set()\n",
    "                    for line in lines:\n",
    "                        if line.strip():\n",
    "                            class_ids.add(int(line.split()[0]))\n",
    "                    \n",
    "                    # Create class names (we'll use generic names)\n",
    "                    class_names = [f\"class_{i}\" for i in sorted(class_ids)]\n",
    "                else:\n",
    "                    # Default to strawberry if we can't determine\n",
    "                    class_names = [\"strawberry\"]\n",
    "            else:\n",
    "                class_names = [\"strawberry\"]\n",
    "            \n",
    "            # Create data.yaml\n",
    "            data_yaml_content = f\"\"\"# Fruit Ripeness Dataset\n",
    "train: {os.path.join(dataset_dir, 'train/images')}\n",
    "val: {os.path.join(dataset_dir, 'valid/images')}\n",
    "test: {os.path.join(dataset_dir, 'test/images') if os.path.exists(os.path.join(dataset_dir, 'test')) else ''}\n",
    "\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\"\"\"\n",
    "            \n",
    "            with open(data_yaml_path, 'w') as f:\n",
    "                f.write(data_yaml_content)\n",
    "            \n",
    "            print(f\"‚úÖ Created data.yaml with {len(class_names)} classes\")\n",
    "        \n",
    "        print(f\"‚úÖ Dataset downloaded and prepared at: {dataset_dir}\")\n",
    "        \n",
    "        # Count images\n",
    "        train_images = list(Path(dataset_dir).glob(\"train/images/*.jpg\")) + list(Path(dataset_dir).glob(\"train/images/*.png\"))\n",
    "        val_images = list(Path(dataset_dir).glob(\"valid/images/*.jpg\")) + list(Path(dataset_dir).glob(\"valid/images/*.png\"))\n",
    "        \n",
    "        print(f\"   Training images: {len(train_images)}\")\n",
    "        print(f\"   Validation images: {len(val_images)}\")\n",
    "        \n",
    "        return dataset_dir\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading dataset: {e}\")\n",
    "        print(\"\\nManual download instructions:\")\n",
    "        print(f\"1. Visit: https://www.kaggle.com/datasets/{kaggle_dataset}\")\n",
    "        print(f\"2. Download the dataset manually\")\n",
    "        print(f\"3. Extract to: {dataset_dir}\")\n",
    "        return None\n",
    "\n",
    "# Download the dataset\n",
    "dataset_path = download_kaggle_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üçì STRAWBERRY DETECTION - YOLOv8 TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# System check\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Recommend batch size\n",
    "    if gpu_memory >= 24:  # RTX 3090/A5000\n",
    "        batch_size_m, batch_size_l = 48, 32\n",
    "    elif gpu_memory >= 10:  # RTX 3080\n",
    "        batch_size_m, batch_size_l = 24, 16\n",
    "    elif gpu_memory >= 8:   # RTX 3070/2070\n",
    "        batch_size_m, batch_size_l = 16, 8\n",
    "    else:\n",
    "        batch_size_m, batch_size_l = 8, 4\n",
    "    print(f\"Recommended batch size - YOLOv8m: {batch_size_m}, YOLOv8l: {batch_size_l}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No GPU detected! Training will be VERY slow on CPU.\")\n",
    "    batch_size_m, batch_size_l = 4, 2\n",
    "\n",
    "print(f\"Ultralytics: {ultralytics.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset\n",
    "dataset_path = \"model/dataset_strawberry_kaggle\"\n",
    "data_yaml = os.path.join(dataset_path, \"data.yaml\")\n",
    "\n",
    "if os.path.exists(data_yaml):\n",
    "    print(f\"‚úÖ Dataset found: {data_yaml}\")\n",
    "    with open(data_yaml, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    print(f\"   Classes: {data.get('nc', 'N/A')}\")\n",
    "    print(f\"   Class names: {data.get('names', 'N/A')}\")\n",
    "    \n",
    "    # Check train/val paths\n",
    "    train_path = data.get('train', '')\n",
    "    val_path = data.get('val', '')\n",
    "    \n",
    "    # Fix relative paths if needed\n",
    "    if train_path.startswith('../'):\n",
    "        train_path = os.path.join(os.path.dirname(data_yaml), train_path)\n",
    "    if val_path.startswith('../'):\n",
    "        val_path = os.path.join(os.path.dirname(data_yaml), val_path)\n",
    "    \n",
    "    # Also check for train/images structure\n",
    "    if not os.path.exists(train_path):\n",
    "        # Try alternative paths\n",
    "        alt_train_path = os.path.join(dataset_path, \"train/images\")\n",
    "        if os.path.exists(alt_train_path):\n",
    "            train_path = alt_train_path\n",
    "            print(f\"   Using alternative train path: {train_path}\")\n",
    "    \n",
    "    if not os.path.exists(val_path):\n",
    "        alt_val_path = os.path.join(dataset_path, \"valid/images\")\n",
    "        if os.path.exists(alt_val_path):\n",
    "            val_path = alt_val_path\n",
    "            print(f\"   Using alternative val path: {val_path}\")\n",
    "    \n",
    "    if train_path and os.path.exists(train_path):\n",
    "        train_images = list(Path(train_path).glob(\"*.jpg\")) + list(Path(train_path).glob(\"*.png\"))\n",
    "        print(f\"   Training images: {len(train_images)}\")\n",
    "    \n",
    "    if val_path and os.path.exists(val_path):\n",
    "        val_images = list(Path(val_path).glob(\"*.jpg\")) + list(Path(val_path).glob(\"*.png\"))\n",
    "        print(f\"   Validation images: {len(val_images)}\")\n",
    "else:\n",
    "    print(f\"‚ùå Dataset not found: {data_yaml}\")\n",
    "    print(\"Please ensure the dataset is in the correct location.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def show_sample_images(num_samples=3):\n",
    "    \"\"\"Display sample images from the dataset.\"\"\"\n",
    "    if not os.path.exists(data_yaml):\n",
    "        print(\"Dataset not found, skipping visualization\")\n",
    "        return\n",
    "    \n",
    "    with open(data_yaml, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    train_path = config.get('train', '')\n",
    "    \n",
    "    # Fix relative paths if needed\n",
    "    if train_path.startswith('../'):\n",
    "        train_path = os.path.join(os.path.dirname(data_yaml), train_path)\n",
    "    \n",
    "    # Also check for train/images structure\n",
    "    if not os.path.exists(train_path):\n",
    "        alt_train_path = os.path.join(dataset_path, \"train/images\")\n",
    "        if os.path.exists(alt_train_path):\n",
    "            train_path = alt_train_path\n",
    "            print(f\"Using train path: {train_path}\")\n",
    "        else:\n",
    "            print(f\"Training path not found: {train_path}\")\n",
    "            return\n",
    "    \n",
    "    image_files = list(Path(train_path).glob(\"*.jpg\")) + list(Path(train_path).glob(\"*.png\"))\n",
    "    if not image_files:\n",
    "        # Try to find images in subdirectories\n",
    "        image_files = list(Path(train_path).rglob(\"*.jpg\")) + list(Path(train_path).rglob(\"*.png\"))\n",
    "        \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {train_path}\")\n",
    "        print(\"Checking directory structure...\")\n",
    "        !find {dataset_path} -name \"*.jpg\" | head -5\n",
    "        return\n",
    "    \n",
    "    samples = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(samples), figsize=(15, 5))\n",
    "    if len(samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (ax, img_path) in enumerate(zip(axes, samples)):\n",
    "        try:\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                ax.text(0.5, 0.5, f\"Failed to load\\n{img_path.name}\", ha='center', va='center')\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "                \n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"Sample {idx+1}\\n{img_path.name}\")\n",
    "            ax.axis('off')\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Error\\n{str(e)[:30]}\", ha='center', va='center')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"üì∏ Displayed {len(samples)} sample images from {train_path}\")\n",
    "\n",
    "# Show samples\n",
    "show_sample_images(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "def train_model(model_size=\"m\", epochs=120, batch_size=24):\n",
    "    \"\"\"Train YOLOv8 model with given parameters.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üöÄ STARTING YOLOv8{model_size.upper()} TRAINING\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Model: yolov8{model_size}.pt\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Batch Size: {batch_size}\")\n",
    "    print(f\"Dataset: {data_yaml}\")\n",
    "    \n",
    "    # Configuration\n",
    "    config = {\n",
    "        \"model\": f\"yolov8{model_size}.pt\",\n",
    "        \"data\": data_yaml,\n",
    "        \"epochs\": epochs,\n",
    "        \"imgsz\": 640,\n",
    "        \"batch\": batch_size,\n",
    "        \"workers\": 8,\n",
    "        \"device\": 0 if torch.cuda.is_available() else \"cpu\",\n",
    "        \"project\": \"model/detection\",\n",
    "        \"name\": f\"yolov8{model_size}_direct\",\n",
    "        \"exist_ok\": True,\n",
    "        \"pretrained\": True,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"lr0\": 0.01 if model_size == \"m\" else 0.008,\n",
    "        \"amp\": True,  # Mixed precision\n",
    "        \"plots\": True,\n",
    "        \"save_period\": 10,\n",
    "        \"val\": True,\n",
    "        \"save\": True,\n",
    "        \"verbose\": True,\n",
    "    }\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = os.path.join(\"model/detection\", f\"yolov8{model_size}_direct\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Start training\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(f\"yolov8{model_size}.pt\")\n",
    "        results = model.train(**config)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        hours = int(training_time // 3600)\n",
    "        minutes = int((training_time % 3600) // 60)\n",
    "        seconds = int(training_time % 60)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"‚úÖ TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"‚è±Ô∏è  Time: {hours}h {minutes}m {seconds}s\")\n",
    "        print(f\"üìÅ Results saved to: {output_dir}\")\n",
    "        \n",
    "        if hasattr(results, 'results_dict'):\n",
    "            metrics = results.results_dict\n",
    "            print(f\"üìä Final mAP@50: {metrics.get('metrics/mAP50(B)', 'N/A'):.4f}\")\n",
    "            print(f\"üìä Final mAP@50-95: {metrics.get('metrics/mAP50-95(B)', 'N/A'):.4f}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Train YOLOv8m (Medium Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv8m\n",
    "print(\"‚ö†Ô∏è  YOLOv8m Training - Estimated: 3-4 hours on RTX 3080\")\n",
    "print(\"üí∞ Estimated cost on cloud: $0.51-$0.68 (at $0.17/hr)\")\n",
    "\n",
    "response = input(\"\\nStart YOLOv8m training? (yes/no): \")\n",
    "\n",
    "if response.lower() == 'yes':\n",
    "    print(\"Starting YOLOv8m training...\")\n",
    "    results_m = train_model(model_size=\"m\", epochs=120, batch_size=batch_size_m)\n",
    "    \n",
    "    if results_m:\n",
    "        print(\"\\nüéâ YOLOv8m training completed!\")\n",
    "        print(\"Next: You can train YOLOv8l or download the model.\")\n",
    "else:\n",
    "    print(\"Skipping YOLOv8m training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Train YOLOv8l (Large Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv8l (optional)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"YOLOv8l Training - Estimated: 4-5 hours on RTX 3080\")\n",
    "print(\"üí∞ Estimated cost on cloud: $0.68-$0.85 (at $0.17/hr)\")\n",
    "\n",
    "response = input(\"\\nStart YOLOv8l training? (yes/no): \")\n",
    "\n",
    "if response.lower() == 'yes':\n",
    "    print(\"Starting YOLOv8l training...\")\n",
    "    results_l = train_model(model_size=\"l\", epochs=150, batch_size=batch_size_l)\n",
    "    \n",
    "    if results_l:\n",
    "        print(\"\\nüéâ YOLOv8l training completed!\")\n",
    "        print(\"Both models are now ready for use.\")\n",
    "else:\n",
    "    print(\"Skipping YOLOv8l training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_progress(model_size=\"m\"):\n",
    "    \"\"\"Monitor training progress.\"\"\"\n",
    "    results_dir = f\"model/detection/yolov8{model_size}_direct\"\n",
    "    results_csv = os.path.join(results_dir, \"results.csv\")\n",
    "    \n",
    "    if not os.path.exists(results_csv):\n",
    "        print(f\"Results not found: {results_csv}\")\n",
    "        return\n",
    "    \n",
    "    df = pd.read_csv(results_csv)\n",
    "    \n",
    "    print(f\"\\nüìä YOLOv8{model_size.upper()} Training Progress\")\n",
    "    print(f\"Epochs completed: {len(df)}\")\n",
    "    \n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        latest_map = df['metrics/mAP50(B)'].iloc[-1]\n",
    "        print(f\"Latest mAP@50: {latest_map:.4f}\")\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    if 'train/box_loss' in df.columns:\n",
    "        axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Box Loss')\n",
    "        axes[0, 0].set_title('Box Loss')\n",
    "        axes[0, 0].grid(True)\n",
    "    \n",
    "    if 'train/cls_loss' in df.columns:\n",
    "        axes[0, 1].plot(df['epoch'], df['train/cls_loss'], label='Class Loss', color='orange')\n",
    "        axes[0, 1].set_title('Class Loss')\n",
    "        axes[0, 1].grid(True)\n",
    "    \n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        axes[1, 0].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@50', color='green')\n",
    "        axes[1, 0].set_title('mAP@50')\n",
    "        axes[1, 0].grid(True)\n",
    "    \n",
    "    if 'lr/pg0' in df.columns:\n",
    "        axes[1, 1].plot(df['epoch'], df['lr/pg0'], label='Learning Rate', color='red')\n",
    "        axes[1, 1].set_title('Learning Rate')\n",
    "        axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor YOLOv8m progress\n",
    "try:\n",
    "    monitor_progress(\"m\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not monitor progress: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor YOLOv8l progress\n",
    "try:\n",
    "    monitor_progress(\"l\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not monitor progress: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Package Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def package_models():\n",
    "    \"\"\"Package trained models for download.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    zip_filename = f\"strawberry_yolov8_models_{timestamp}.zip\"\n",
    "    \n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for model_size in ['m', 'l']:\n",
    "            model_dir = f\"model/detection/yolov8{model_size}_direct\"\n",
    "            best_pt = os.path.join(model_dir, \"weights\", \"best.pt\")\n",
    "            \n",
    "            if os.path.exists(best_pt):\n",
    "                zipf.write(best_pt, f\"yolov8{model_size}/best.pt\")\n",
    "                print(f\"‚úÖ Added yolov8{model_size}/best.pt\")\n",
    "            \n",
    "            # Add results\n",
    "            results_csv = os.path.join(model_dir, \"results.csv\")\n",
    "            if os.path.exists(results_csv):\n",
    "                zipf.write(results_csv, f\"yolov8{model_size}/results.csv\")\n",
    "                print(f\"‚úÖ Added yolov8{model_size}/results.csv\")\n",
    "    \n",
    "    size_mb = os.path.getsize(zip_filename) / 1024 / 1024\n",
    "    print(f\"\\nüì¶ Models packaged: {zip_filename} ({size_mb:.2f} MB)\")\n",
    "    print(\"\\nTo download:\")\n",
    "    print(f\"1. Right-click '{zip_filename}' in Jupyter file browser\")\n",
    "    print(f\"2. Select 'Download'\")\n",
    "    print(f\"3. Or use: `!cp {zip_filename} /mnt/` if mounted\")\n",
    "    \n",
    "    return zip_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package models\n",
    "print(\"Packaging trained models...\")\n",
    "try:\n",
    "    zip_file = package_models()\n",
    "    print(f\"\\n‚úÖ Ready for download: {zip_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Next Steps After Training\n",
    "\n",
    "1. **Download the models** using the zip file above\n",
    "2. **Test inference** with the trained models:\n",
    "   ```python\n",
    "   from ultralytics import YOLO\n",
    "   model = YOLO('model/detection/yolov8m_direct/weights/best.pt')\n",
    "   results = model('path/to/image.jpg')\n",
    "   ```\n",
    "\n",
    "3. **Convert to ONNX** for faster inference:\n",
    "   ```python\n",
    "   model.export(format='onnx')\n",
    "   ```\n",
    "\n",
    "4. **Deploy to Raspberry Pi** using ONNX Runtime\n",
    "\n",
    "## üìä Expected Performance\n",
    "\n",
    "- **YOLOv8m**: ~99.0% mAP@50, 25-30 FPS on Raspberry Pi 4\n",
    "- **YOLOv8l**: ~99.2% mAP@50, 15-20 FPS on Raspberry Pi 4\n",
    "\n",
    "## üÜò Troubleshooting\n",
    "\n",
    "- **Out of memory**: Reduce batch size\n",
    "- **Slow training**: Ensure GPU is being used\n",
    "- **Dataset issues**: Check `model/dataset_strawberry_kaggle/data.yaml`\n",
    "- **Installation problems**: Run `!pip install ultralytics --upgrade`\n",
    "- **Kaggle authentication**: If download fails, manually download from https://www.kaggle.com/datasets/dudinurdiyansah/fruit-ripeness-dataset\n",
    "\n",
    "## üìû Support\n",
    "\n",
    "- Check the main project README.md\n",
    "- Review training logs in `model/detection/yolov8*_direct/`\n",
    "- Monitor GPU usage with `!nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final status check\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_size in ['m', 'l']:\n",
    "    model_dir = f\"model/detection/yolov8{model_size}_direct\"\n",
    "    best_pt = os.path.join(model_dir, \"weights\", \"best.pt\")\n",
    "    \n",
    "    if os.path.exists(best_pt):\n",
    "        size_mb = os.path.getsize(best_pt) / 1024 / 1024\n",
    "        print(f\"‚úÖ YOLOv8{model_size.upper()}: {size_mb:.1f} MB at {best_pt}\")\n",
    "    else:\n",
    "        print(f\"‚è≥ YOLOv8{model_size.upper()}: Not trained yet\")\n",
    "\n",
    "print(\"\\nüìÅ All models saved in: model/detection/\")\n",
    "print(\"üì¶ Package ready: strawberry_yolov8_models_*.zip\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}